{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "from util import preprocessData, createFeatures\n",
    "\n",
    "(ratings, reviews) = preprocessData('sportsTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a dictionary\n",
    "dic = {}\n",
    "for review in reviews:\n",
    "    for word in review.split():\n",
    "        dic[word] = dic.get(word, 0) + 1\n",
    "print(len(dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping words that occurs over 500 times\n",
    "occurenceThreshold = 500\n",
    "wordToIndex = {}\n",
    "indexToWord = []\n",
    "for key, value in dic.items():\n",
    "    if value > occurenceThreshold:\n",
    "        indexToWord.append(key)\n",
    "        wordToIndex[key] = len(indexToWord) - 1\n",
    "n = len(wordToIndex)\n",
    "print(len(wordToIndex), len(indexToWord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ratingsVal, reviewsVal) = preprocessData('sportsDev.csv')\n",
    "print(len(ratingsVal))\n",
    "(Xval, yval) = createFeatures(reviewsVal, ratingsVal, wordToIndex, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ratingsTest, reviewsTest) = preprocessData('sportsTest.csv')\n",
    "print(len(ratingsTest))\n",
    "(Xtest, ytest) = createFeatures(reviewsTest, ratingsTest, wordToIndex, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a more balanced training set\n",
    "import random\n",
    "\n",
    "max_sample = 80000\n",
    "classes = [[] for i in range(5)]\n",
    "for i in range(len(ratings)):\n",
    "    r = ratings[i]\n",
    "    classes[r-1].append(i)\n",
    "\n",
    "indices_balanced = []\n",
    "for i in range(5):\n",
    "    indices = random.sample(classes[i], max_sample)\n",
    "    indices_balanced += indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(indices_balanced)\n",
    "reviews = [reviews[i] for i in indices_balanced]\n",
    "ratings = [ratings[i] for i in indices_balanced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from util import evalModel\n",
    "\n",
    "# Plotting the learning curve\n",
    "trainSizes = [1000, 5000, 10000, 30000, 50000, 70000, 100000]\n",
    "trainAccs = []\n",
    "valAccs = []\n",
    "trainF1s = []\n",
    "valF1s = []\n",
    "\n",
    "for trainSize in trainSizes:\n",
    "    # create feature vector and labels\n",
    "    (X, y) = createFeatures(reviews, ratings, wordToIndex, trainSize)\n",
    "    # train a linear model\n",
    "    svmModel = LinearSVC(dual = False, max_iter=5000).fit(X, y)\n",
    "    (valAcc, valF1, _) = evalModel(svmModel.predict(Xval), yval)\n",
    "    (trainAcc, trainF1, _) = evalModel(svmModel.predict(X), y)\n",
    "    trainAccs.append(trainAcc)\n",
    "    valAccs.append(valAcc)\n",
    "    trainF1s.append(trainF1)\n",
    "    valF1s.append(valF1)\n",
    "\n",
    "# plot\n",
    "plt.title('Learning Curve Using Accuracy')\n",
    "plt.plot(trainSizes, trainAccs, 'bo-', label = 'training')\n",
    "plt.plot(trainSizes, valAccs, 'ro-', label = 'validation')\n",
    "plt.xlabel('Number of Training Examples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Learning Curve Using F1 Score')\n",
    "plt.plot(trainSizes, trainF1s, 'bo-', label = 'training')\n",
    "plt.plot(trainSizes, valF1s, 'ro-', label = 'validation')\n",
    "plt.xlabel('Number of Training Examples')\n",
    "plt.ylabel('Average F1 Score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(testAcc, testF1, confM) = evalModel(svmModel.predict(Xtest), ytest)\n",
    "print(testAcc)\n",
    "print(testF1)\n",
    "print(confM.astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from util import evalModel\n",
    "\n",
    "# Plotting the learning curve\n",
    "trainSizes = [30000, 50000, 70000, 100000, 200000, 400000]\n",
    "trainAccs = []\n",
    "valAccs = []\n",
    "trainF1s = []\n",
    "valF1s = []\n",
    "maxDataSize = 100000\n",
    "\n",
    "for trainSize in trainSizes:\n",
    "    # train a linear model\n",
    "    svmModel = None\n",
    "    if trainSize > maxDataSize:\n",
    "        for i in range(trainSize // maxDataSize):\n",
    "            (X, y) = createFeatures(reviews[i*maxDataSize:(i+1)*maxDataSize],\\\n",
    "                                    ratings[i*maxDataSize:(i+1)*maxDataSize],\\\n",
    "                                    wordToIndex, maxDataSize)\n",
    "            svmModel = SGDClassifier(max_iter=1000, loss='squared_hinge'\\\n",
    "                                     , warm_start = True).fit(X, y)\n",
    "    else:\n",
    "        (X, y) = createFeatures(reviews, ratings, wordToIndex, trainSize)\n",
    "        svmModel = SGDClassifier(max_iter=1000, loss='squared_hinge').fit(X, y)\n",
    "    (valAcc, valF1, _) = evalModel(svmModel.predict(Xval), yval)\n",
    "    (trainAcc, trainF1, _) = evalModel(svmModel.predict(X), y)\n",
    "    trainAccs.append(trainAcc)\n",
    "    valAccs.append(valAcc)\n",
    "    trainF1s.append(trainF1)\n",
    "    valF1s.append(valF1)\n",
    "\n",
    "# plot\n",
    "plt.title('Learning Curve Using Accuracy')\n",
    "plt.plot(trainSizes, trainAccs, 'bo-', label = 'training')\n",
    "plt.plot(trainSizes, valAccs, 'ro-', label = 'validation')\n",
    "plt.xlabel('Number of Training Examples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Learning Curve Using F1 Score')\n",
    "plt.plot(trainSizes, trainF1s, 'bo-', label = 'training')\n",
    "plt.plot(trainSizes, valF1s, 'ro-', label = 'validation')\n",
    "plt.xlabel('Number of Training Examples')\n",
    "plt.ylabel('Average F1 Score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(testAcc, testF1, confM) = evalModel(svmModel.predict(Xtest), ytest)\n",
    "print(testAcc)\n",
    "print(testF1)\n",
    "print(confM.astype(np.int))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
